image: $CI_REGISTRY/signageos/docker-node:12.16.1-alpine-build-zip-vips-ffmpeg
services:
  - docker:dind

stages:
  - prepare
  - test
  - build:npm
  - build:apk-files
  - build:apk
  - publish
  - build:apks-repo
  - build:overlay-and-cache
  - build:image
  - release

cache: &cache
  key: "${CI_PROJECT_ID}_node_modules"
  paths:
    - node_modules/
  policy: pull-push

before_script:
  - npm config set unsafe-perm true
  - export VERSION=`cat ./VERSION`
  - export TAG=$([ "$CI_COMMIT_TAG" == "" ] && echo $CI_COMMIT_REF_NAME || echo $(echo ${VERSION}-latest | sed -E 's/^[0-9]+.[0-9]+.[0-9]+-([a-zA-Z0-9]+)(\.[0-9]+)?(-[a-zA-Z0-9]+)?$/\1/p' | tail -n1))
  - npx @signageos/lib@just-tools version-upgrade $VERSION
  - npm install

prepare:
  image: $CI_REGISTRY/signageos/docker:master
  stage: prepare
  cache: {}
  before_script: []
  script:
    - ci-prepare
  artifacts:
    when: on_success
    paths:
      - ./VERSION

test:general:
  stage: test
  except:
    - tags
  retry: 2 # sometimes a test fails with a mysterious timeout
  variables:
    fs_root_path: /test_fs
    fs_system_path: /test_system_fs
  script:
    - npm test
    - make test
  cache:
    <<: *cache
    policy: pull

test:lint:
  stage: test
  cache:
    <<: *cache
    policy: pull
  except:
    - tags
  script:
    - if [ `find test* -type f -print0 | xargs -0 grep "\.only" | wc -l` -gt 0 ]; then echo "You forgot the .only in tests" && exit 1; fi
    - npm run lint

test:changelog:
  image: $CI_REGISTRY/signageos/docker:master
  stage: test
  cache:
    <<: *cache
    policy: pull
  except:
    - tags
  allow_failure: true
  script:
    - ci-test-changelog

build:npm:
  stage: build:npm
  dependencies:
    - prepare
  script:
    - npm run build --production
  artifacts:
    when: on_success
    paths:
      - dist/

.build:apk-files:
  stage: build:apk-files
  dependencies:
    - prepare
    - build:npm
  before_script: []
  script:
    - VERSION=`cat ./VERSION`
    - tools/prepare-apkbuild.sh $TARGET $VERSION
  artifacts:
    when: on_success
    paths:
      - dist/$TARGET

build:apk-files-rpi:
  extends: .build:apk-files
  cache:
    key: "${CI_PROJECT_ID}_dist_node_modules_rpi"
    paths:
      - dist/server/node_modules
      - rpi/api/network/node_modules
      - rpi/api/nec/node_modules
  tags:
    - alpine
    - armhf
  variables:
    TARGET: rpi

.build:alpine:
  stage: build:apk
  cache: {}
  before_script: []
  script:
    - sudo apk update
    - REPO=`pwd`/packages
    - tools/build-apk.sh $TARGET $REPO
  artifacts:
    when: on_success
    paths:
      - packages/dist/$ARCHITECTURE

build:alpine-rpi:
  extends: .build:alpine
  dependencies:
    - prepare
    - build:npm
    - build:apk-files-rpi
  tags:
    - alpine
    - armhf
  variables:
    ARCHITECTURE: armhf
    TARGET: rpi

.publish:alpine:
  image: $CI_REGISTRY/signageos/docker-alpine:master
  stage: publish
  cache: {}
  before_script: []
  script:
    - S3_REPO_PATH="s3://signageos-alpine-repository/1.0/sos/$ARCHITECTURE"
    - aws s3 cp packages/dist/$ARCHITECTURE "$S3_REPO_PATH" --recursive --exclude "*" --include "*.apk"

publish:alpine-rpi:
  extends: .publish:alpine
  dependencies:
    - build:alpine-rpi
  variables:
    ARCHITECTURE: armhf
    TARGET: rpi

publish:npm:
  stage: publish
  cache:
    <<: *cache
    policy: pull
  dependencies:
    - prepare
    - build:npm
    - build:apk-files-rpi
  script:
    - npm publish --ignore-scripts --tag $TAG

.build:apks:
  stage: build:apks-repo
  cache: {}
  before_script: []
  script:
    - export PRIVATE_KEY_PATH="$ALPINE_PRIVATE_KEY"
    - export PUBLIC_KEY_FILENAME="$ALPINE_PUBLIC_KEY_FILENAME"
    - tools/build-apks-repo.sh
  artifacts:
    when: on_success
    paths:
      - apks-$TARGET.tar.gz

build:apks-rpi:
  extends: .build:apks
  tags:
    - alpine
    - armhf
  variables:
    ARCHITECTURE: armhf
    TARGET: rpi

.build:overlay-and-cache:
  image: $CI_REGISTRY/signageos/docker-alpine/minimal:ma-moreImageTypes # TODO release image and change version
  stage: build:overlay-and-cache
  cache: {}
  retry: 2 # usually the first time it fails because it needs apk from previous job and it takes a moment for it to make it into the repo index
  tags:
    - alpine
    - docker
  before_script: []
  script:
    - export $ARCHITECTURE
    - export VERSION=`cat ./VERSION | sed -r 's/-[^.]+//g' | sed -r 's/\+.+//g'`-r0 # omit branch version
    - tar -xzf apks-$TARGET.tar.gz
    - tools/build-overlay-and-cache.sh sos.apkovl.tar.gz cache.tar.gz
  artifacts:
    when: on_success
    paths:
      - sos.apkovl.tar.gz
      - cache.tar.gz

build:overlay-and-cache-rpi:
  extends: .build:overlay-and-cache
  variables:
    ARCHITECTURE: armhf
    TARGET: rpi
  dependencies:
    - prepare
    - build:apks-rpi

.build:image:
  stage: build:image
  tags:
    - privileged
  before_script: []
  script:
    - VERSION=`cat ./VERSION`
    - docker login -u gitlab-ci-token -p $CI_BUILD_TOKEN $CI_REGISTRY
    - docker pull $CI_REGISTRY/signageos/docker-wpewebkit:2.26.4-$ARCHITECTURE
    - docker tag $CI_REGISTRY/signageos/docker-wpewebkit:2.26.4-$ARCHITECTURE wpewebkit:2.26.4
    - tools/build-image.sh $ARCHITECTURE $VERSION apks-$TARGET.tar.gz alpine-$TARGET.img
  artifacts:
    when: on_success
    paths:
      - alpine-$TARGET.img

build:image-rpi:
  extends: .build:image
  variables:
    ARCHITECTURE: armhf
    TARGET: rpi
  dependencies:
    - prepare
    - build:apks-rpi
    - build:overlay-and-cache-rpi

release:tag:
  image: $CI_REGISTRY/signageos/docker:master
  stage: release
  cache: {}
  only:
    - master
  when: manual
  allow_failure: false
  before_script: []
  script:
    - ci-release-tag

release:notes:
  image: $CI_REGISTRY/signageos/docker:master
  stage: release
  cache:
    <<: *cache
    policy: pull
  only:
    - tags
  script:
    - ci-release-notes
